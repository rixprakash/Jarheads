{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkLWEwtc6ZdR",
        "outputId": "304b837b-9b11-4c1b-c3a4-e82150b04d2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Loading BERT model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ BERT model loaded successfully!\n",
            "üì• Loading trained models...\n",
            "‚úÖ Models loaded successfully!\n",
            "üì• Loading test dataset...\n",
            "‚úÖ Loaded 5675 test samples!\n",
            "üîÑ Converting test lyrics to BERT embeddings...\n",
            "‚úÖ BERT embeddings extracted!\n",
            "üéØ Making predictions...\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\n",
            "üìä Generating Classification Reports...\n",
            "\n",
            "\n",
            "üîç Logistic Regression Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       blues       0.30      0.24      0.27       926\n",
            "     country       0.45      0.52      0.48      1123\n",
            "     hip hop       0.70      0.59      0.64       198\n",
            "        jazz       0.31      0.26      0.28       731\n",
            "         pop       0.36      0.44      0.39      1398\n",
            "      reggae       0.39      0.35      0.37       515\n",
            "        rock       0.36      0.30      0.33       784\n",
            "\n",
            "    accuracy                           0.38      5675\n",
            "   macro avg       0.41      0.39      0.40      5675\n",
            "weighted avg       0.38      0.38      0.37      5675\n",
            "\n",
            "\n",
            "üîç Neural Network Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       blues       0.36      0.13      0.19       926\n",
            "     country       0.38      0.66      0.48      1123\n",
            "     hip hop       1.00      0.28      0.43       198\n",
            "        jazz       0.44      0.10      0.16       731\n",
            "         pop       0.32      0.60      0.41      1398\n",
            "      reggae       0.43      0.33      0.37       515\n",
            "        rock       0.64      0.07      0.13       784\n",
            "\n",
            "    accuracy                           0.36      5675\n",
            "   macro avg       0.51      0.31      0.31      5675\n",
            "weighted avg       0.43      0.36      0.32      5675\n",
            "\n",
            "‚úÖ Classification reports saved to OUTPUT/genre_classification_report_BERT.txt!\n",
            "üìä Creating confusion matrices...\n",
            "‚úÖ Confusion matrices saved to OUTPUT/confusion_matrix_BERT_test.png!\n",
            "\n",
            "üéØ Model Testing Complete! Results saved in OUTPUT/ directory.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import requests\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Ensure GPU is used if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "##############################\n",
        "# 1. Helper Function to Download Files\n",
        "##############################\n",
        "GITHUB_BASE_URL = \"https://raw.githubusercontent.com/rixprakash/Jarheads/main/Project%201/OUTPUT/\"\n",
        "GITHUB_DATA_URL = \"https://raw.githubusercontent.com/rixprakash/Jarheads/main/Project%201/DATA/test_data.csv\"\n",
        "\n",
        "FILES_TO_DOWNLOAD = [\n",
        "    \"logistic_regression_bert.pkl\",\n",
        "    \"neural_network_bert.h5\",\n",
        "    \"label_encoder.pkl\",\n",
        "    \"X_embeddings.npy\",\n",
        "    \"y.npy\"\n",
        "]\n",
        "\n",
        "def download_file(filename, url):\n",
        "    \"\"\"Downloads a file from GitHub repository if it's missing.\"\"\"\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"üì• Downloading {filename} from GitHub...\")\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            with open(filename, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            print(f\"‚úÖ {filename} downloaded successfully!\")\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"‚ùå Failed to download {filename}\")\n",
        "\n",
        "# Ensure required model files exist\n",
        "for file in FILES_TO_DOWNLOAD:\n",
        "    download_file(file, GITHUB_BASE_URL + file)\n",
        "\n",
        "# Ensure test dataset exists\n",
        "download_file(\"test_data.csv\", GITHUB_DATA_URL)\n",
        "\n",
        "##############################\n",
        "# 2. Load Pretrained BERT Model\n",
        "##############################\n",
        "print(\"üì• Loading BERT model...\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
        "print(\"‚úÖ BERT model loaded successfully!\")\n",
        "\n",
        "##############################\n",
        "# 3. Load Trained Models & Label Encoder\n",
        "##############################\n",
        "print(\"üì• Loading trained models...\")\n",
        "logistic_model = joblib.load(\"logistic_regression_bert.pkl\")\n",
        "nn_model = load_model(\"neural_network_bert.h5\")\n",
        "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
        "print(\"‚úÖ Models loaded successfully!\")\n",
        "\n",
        "##############################\n",
        "# 4. Load Test Data\n",
        "##############################\n",
        "print(\"üì• Loading test dataset...\")\n",
        "df_test = pd.read_csv(\"test_data.csv\")\n",
        "test_lyrics = df_test[\"cleaned_lyrics\"].tolist()  # Lyrics to classify\n",
        "true_labels = label_encoder.transform(df_test[\"genre\"])  # Convert genre names to encoded labels\n",
        "print(f\"‚úÖ Loaded {len(test_lyrics)} test samples!\")\n",
        "\n",
        "##############################\n",
        "# 5. Convert Lyrics to BERT Embeddings (Batch Processing)\n",
        "##############################\n",
        "def get_bert_embeddings_batch(texts, batch_size=16):\n",
        "    \"\"\"Converts a batch of lyrics into BERT embeddings with proper GPU handling.\"\"\"\n",
        "    embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]  # Get batch of lyrics\n",
        "        tokens = tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "        tokens = {key: val.to(device) for key, val in tokens.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = bert_model(**tokens)\n",
        "\n",
        "        batch_embeddings = output.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "        embeddings.extend(batch_embeddings)\n",
        "\n",
        "    return np.array(embeddings)\n",
        "\n",
        "print(\"üîÑ Converting test lyrics to BERT embeddings...\")\n",
        "X_test_embeddings = get_bert_embeddings_batch(test_lyrics)\n",
        "print(\"‚úÖ BERT embeddings extracted!\")\n",
        "\n",
        "##############################\n",
        "# 6. Make Predictions on Test Data\n",
        "##############################\n",
        "print(\"üéØ Making predictions...\")\n",
        "\n",
        "# Predict with Logistic Regression\n",
        "logreg_preds = logistic_model.predict(X_test_embeddings)\n",
        "\n",
        "# Predict with Neural Network\n",
        "nn_preds = np.argmax(nn_model.predict(X_test_embeddings), axis=1)\n",
        "\n",
        "##############################\n",
        "# 7. Evaluate Model Performance\n",
        "##############################\n",
        "print(\"\\nüìä Generating Classification Reports...\\n\")\n",
        "\n",
        "# Generate reports\n",
        "logreg_report = classification_report(true_labels, logreg_preds, target_names=label_encoder.classes_)\n",
        "nn_report = classification_report(true_labels, nn_preds, target_names=label_encoder.classes_)\n",
        "\n",
        "print(\"\\nüîç Logistic Regression Report:\\n\", logreg_report)\n",
        "print(\"\\nüîç Neural Network Report:\\n\", nn_report)\n",
        "\n",
        "# Ensure OUTPUT directory exists\n",
        "os.makedirs(\"OUTPUT\", exist_ok=True)\n",
        "\n",
        "# Save reports\n",
        "with open(\"OUTPUT/genre_classification_report_BERT.txt\", \"w\") as f:\n",
        "    f.write(\"Logistic Regression Classification Report:\\n\")\n",
        "    f.write(logreg_report + \"\\n\\n\")\n",
        "    f.write(\"Neural Network Classification Report:\\n\")\n",
        "    f.write(nn_report)\n",
        "print(\"‚úÖ Classification reports saved to OUTPUT/genre_classification_report_BERT.txt!\")\n",
        "\n",
        "##############################\n",
        "# 8. Generate & Save Confusion Matrices\n",
        "##############################\n",
        "def save_confusion_matrices():\n",
        "    \"\"\"Creates and saves confusion matrices.\"\"\"\n",
        "    print(\"üìä Creating confusion matrices...\")\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "    # Logistic Regression Confusion Matrix\n",
        "    sns.heatmap(confusion_matrix(true_labels, logreg_preds), annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_, ax=axes[0])\n",
        "    axes[0].set_title(\"Confusion Matrix - Logistic Regression\")\n",
        "    axes[0].set_xlabel(\"Predicted\")\n",
        "    axes[0].set_ylabel(\"Actual\")\n",
        "\n",
        "    # Neural Network Confusion Matrix\n",
        "    sns.heatmap(confusion_matrix(true_labels, nn_preds), annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_, ax=axes[1])\n",
        "    axes[1].set_title(\"Confusion Matrix - Neural Network\")\n",
        "    axes[1].set_xlabel(\"Predicted\")\n",
        "    axes[1].set_ylabel(\"Actual\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"OUTPUT/confusion_matrix_BERT_test.png\")\n",
        "    plt.close()\n",
        "    print(\"‚úÖ Confusion matrices saved to OUTPUT/confusion_matrix_BERT_test.png!\")\n",
        "\n",
        "save_confusion_matrices()\n",
        "\n",
        "print(\"\\nüéØ Model Testing Complete! Results saved in OUTPUT/ directory.\")"
      ]
    }
  ]
}